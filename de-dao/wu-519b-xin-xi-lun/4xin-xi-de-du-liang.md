对于一条信息，重要的是找出其中有多少信息量，要搞清楚信息量，又要对信息进行量化的度量。

香农提出了度量信息量的基本单位，也就是说前面说到的“比特”。“比特”是这样定义的：如果一个黑盒子中有A和B两种可能性，他们出现的概率相同，那么要搞清楚到底是A还是B，所需要的信息就是1比特。如果知道A的概率比B大，那么解密它们所需要的信息就不到1比特。如果要确定四选一的问题答案需要2比特信息，确定32个球队谁是冠军需要5比特信息。

我们把充满不确定性的黑盒子就叫做信息源，它里面的不确定性叫“信息熵”，而“信息”就是用来消除这些不确定性的，所以**搞清楚黑盒子里是怎么回事，需要的“信息量”就等于黑盒子里的“信息熵”**。

熵是一个热力学的概念，表示一个系统的无序状态。信息熵表示一个系统内部的不确定性。一个系统中的状态数量，也就是说可能性越多，不确定性就越大；在状态数量保持不变时，如果各个状态的可能性相同，不确定性就很大；如果个别状态容易发生，大部分状态都不可能发生，不确定性就小。

信息熵的公式：

H\(p1, p2, …, pn\)= -\(p1\*ln p1 + p2\*ln p2 + … + pn\*ln pn\)

信息量的大小不在于长短，而在于开创了多少新知。

