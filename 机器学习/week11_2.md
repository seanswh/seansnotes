1.人为扩展数据集
机器学习模型的训练中，我们往往需要大量的数据。而这些数据从哪里来呢？我们可以用Artificial Data Synthesis（人工数据合成）。
如下图，假设我们收集了一个文字识别的数据集（图像+字母标记），我们如何将它”扩大“呢？
![](/机器学习/images/113.PNG)
对于文字识别来说，可以通过变形、旋转、缩放来增加样本,对于音频来说，可以通过增加噪音来扩大样本。要注意的是，所添加的噪音/扭曲必须是在对应类型的数据集中比较有代表性的噪音/扭曲。

获得更多数据的注意事项：

确认使用的是low bias的分类器（通过画学习曲线来判别）（如果是high bias的分类器，增加样本数量对提升模型性能已经不太有用了【见前面】，这时要增加训练特征数目，比如在神经网络里可以增加隐藏层的神经元数目）
![](/机器学习/images/114.PNG)
注意获得更多数据的投入成本。考虑到所付出的工作和模型可能从更多的数据中获得的性能改善，作出权衡。（不同的三种途径：人工合成，自己搜集，众筹）

2.Ceiling Analysis：上限分析

前面学到，机器学习的过程使用到了“流水线"的概念，我们希望在改善机器学习系统的性能时，把更多的精力投入到流水线中性价比较高的地方，即改善的努力最有可能得到回报的部分，那么，我们就需要首先找出当前是系统的哪个部分对系统的性能限制最大。

如下图，回到文字识别问题，我们对识别系统的不同组件（component）的准确度进行对
比：