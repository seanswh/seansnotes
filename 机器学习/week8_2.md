1.数据压缩
用于将样例数据的Feature维度数减小，2D->1D,3D->2D
2.工具 PCA(Principal Component Analysis)
用向量(vector)方法压缩维度，如下图所示：
![](/机器学习/images/72.PNG)
具体执行过程：
（1）对输入样本集进行标准化预处理
![](/机器学习/images/73.PNG)
（2）计算输入样本矩阵的特征向量 $$\Sigma= \frac{1}{m}\sum_{i=1}^{n}(x^{(i)})(x^{(i)})^T$$
（3）使用octave中的svd方法计算向量 [u,s,v] = svd(Sigma);其中u即为结果矩阵，如果需要降维到k，则从u中取前k列即可。
![](/机器学习/images/74.PNG)
3.还原
我们将原来的样本数据集从n维(x)降维到k维（z）,那如何从Z还原回X呢？
公式： $$x_{approx} = U_{reduce}* z$$

4. 如何确定K的大小？
原则如下图所示：
![](/机器学习/images/75.png)
按照传统的计算方式，计算过程会比较复杂，如下图左侧所示，但是上一节中介绍的SVD工具中有一个返回参数s，这是一个n*n的矩阵，n是原始样本集中的feature维度，这个矩阵对角线上的值是K取从1到N时的各个$$\Sigma$$,因此可以使用下图右侧的公式快速进行计算：
![](/机器学习/images/76.png)