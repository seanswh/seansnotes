1.Error Metrics for Skewed Data
比如当前有这样一个情况：預測病人是否得到腫瘤，如果通过训练，我们的算法誤差率是1%(99%的準確率)。但是如果我们知道，所有的样本中，得癌症得比例只有0.5%,那如果我们“改良”一下算法——对所有样本，结果均是“没有癌症”，那“改良”后得算法正确率会提升到99.5%,误差率为0.5%,降低了一半哦~~那这个“改进”能称之为“优化”么？
显然不能~
那就牵扯出一个问题：到底应该如何评估一个算法是”改善“了呢？
我们使用precision和recall来评估~如下图所示：
![](/机器学习/images/57.png)

True positive：預測為1，實際也為1
False positive：預測為1，實際為0
False negative：預測為0，實際為1
True negative：預測為0，實際也為0

Precision: 預測為1的狀況下，實際的值為1的比率